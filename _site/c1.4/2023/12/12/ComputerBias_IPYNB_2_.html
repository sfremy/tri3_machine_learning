<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Computing Bias | CompSci Blogs</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Computing Bias" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction to Computing Bias A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription." />
<meta property="og:description" content="Introduction to Computing Bias A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription." />
<link rel="canonical" href="http://0.0.0.0:4200/csablog/c1.4/2023/12/12/ComputerBias_IPYNB_2_.html" />
<meta property="og:url" content="http://0.0.0.0:4200/csablog/c1.4/2023/12/12/ComputerBias_IPYNB_2_.html" />
<meta property="og:site_name" content="CompSci Blogs" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-12-12T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Computing Bias" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-12-12T00:00:00-08:00","datePublished":"2023-12-12T00:00:00-08:00","description":"Introduction to Computing Bias A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription.","headline":"Computing Bias","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4200/csablog/c1.4/2023/12/12/ComputerBias_IPYNB_2_.html"},"url":"http://0.0.0.0:4200/csablog/c1.4/2023/12/12/ComputerBias_IPYNB_2_.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/csablog/assets/css/style.css?v=63838579fe931db354edc3470df1d250d658967f">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/csablog/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://0.0.0.0:4200/csablog/">CompSci Blogs</a></h1>

        

        <p>August 2023 to June 2024</p>

        
        <p class="view"><a href="https://github.com/sfremy/csablog">View the Project on GitHub <small>sfremy/csablog</small></a></p>
        

        

        <header class="site-header">

  <div id="header">
    <nav>
      <ul>
        <li class="fork"><a href="/csablog/">Home</a></li>
        <li class="fork"><a href="/csablog/csp">CompSci</a></li>
        <li class="fork"><a href="/csablog/blogs">Blogs</a></li>
        <li class="fork"><a href="/csablog/login">Login</a></li>
        <li class="title"><a href="https://github.com/sfremy/csablog#readme">View On GitHub</a></li>
      </ul>
    </nav>
  </div><!-- end header -->
</header>

        
      </header>
      <section>

      <small>12 December 2023</small>
<h1>Computing Bias</h1>

<p class="view">by </p>

<h2 id="introduction-to-computing-bias"><mark>Introduction to Computing Bias</mark></h2>
<p>A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription.</p>

<h2 id="explicit-data-vs-implicit-data"><mark>Explicit Data vs Implicit Data</mark></h2>
<p>Many software apps such as Netflix mentioned previous collect a lot of data. There are two types of data that apps collect and they are Explicit and Implicit.</p>

<h3 id="explicit"><mark>Explicit</mark>:</h3>
<ul>
  <li>Examples:
    <ul>
      <li>Name</li>
      <li>Adress
        <h3 id="implicit"><mark>Implicit</mark>:</h3>
      </li>
    </ul>
  </li>
  <li>Examples(Netflix):
    <ul>
      <li>What you watch</li>
      <li>When you watched</li>
      <li>Engagement(Watch Retention)</li>
      <li>Types of movies or shows</li>
    </ul>
  </li>
</ul>

<h2 id="popcorn-hack-1"><font color="ADD8E6">Popcorn Hack 1</font></h2>
<p>Name a software app you know about and name some explicit and some implicit data that they collect from you the user.</p>

<p>Answer: Facebook obtains your email address and some personal information (don’t know, never used) and then tracks your connections with other users and viewership of certain content categories.</p>

<h2 id="loan-company-example"><mark>Loan Company Example</mark></h2>
<p>Another bias can be observed in trends. In the context of an app that collects information for loan officers to help them decide who the best candidate is to give a loan to, trends, for example, could show that a certain age group is comprised of better candidates for a loan. This bias is based on trends and data, and it could be beneficial to the loan officers, preventing them from losing money on loans and avoiding complications with the loanee. However, this could be harmful to the candidate applying for the loan because they might be turned away simply because they don’t qualify within a certain age or race bracket.</p>

<h2 id="example-2">Example #2</h2>
<ul>
  <li><mark>Movies</mark>
    <ul>
      <li>A movie such as Dispicable Me has more of a demographic for younger people. Even though this is a bias is is beneficial because it is content that is specific to someones wants.</li>
      <li>Movies such as Star Wars are more geared toward older poeple as their target audence in contrary to a cartoon.</li>
    </ul>
  </li>
  <li><mark>Video Games</mark>
    <ul>
      <li>Casual Audience: These games are has a bias towards an audience that want to play casually
        <ul>
          <li>Candy Crush</li>
          <li>Minecraft</li>
        </ul>
      </li>
      <li>Sweaty Games: These have more of a bias for people that want to get better and play competitively
        <ul>
          <li>Counter Strike</li>
          <li>Call of Duty</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="popcorn-hack-2"><font color="ADD8E6">Popcorn Hack 2</font></h2>
<p>Give an example of a movie, show, or video game or even a certain softare that has a certain bias and what who the bias is towards</p>

<p>Answer: Scipy Python package is biased towards professional researchers, as its documentation makes use of many advanced statistical terms despite some functions being overall fairly simple to use (e.g. drawing samples from skewed normal distributions).</p>

<h2 id="mitigating-bias-in-algorithms"><mark>Mitigating Bias in Algorithms</mark></h2>

<p>To address  human biases, programmers must work towards minimizing bias in algorithms used for computing innovations. Software should aim for neutrality, considering all perspectives and actively rejecting inherent human biases.</p>

<p>Key considerations during program development:</p>

<ul>
  <li>Identify potential sources of bias.</li>
  <li>Assess whether your program is amplifying or intentionally excluding certain elements.</li>
  <li>Solicit feedback from a diverse and widespread group of individuals.</li>
  <li>Contemplate how people who differ from you might utilize your developments.</li>
</ul>

<h2 id="questions-to-ask-about-bias">Questions to ask About Bias</h2>
<ul>
  <li>
    <p>In the example of the Loan Company the bias was unintentional but could be potentially excluding fit candidates. In the example of Netflix, the bias of adding exclusives in the front of categories is intentianal but not harmful for anyone. This leads to some questions to ask if you encounter bias in a software.</p>
  </li>
  <li>
    <p><mark>Questions</mark>:</p>
    <ul>
      <li>Is it enhancing or intentionally excluding?</li>
      <li>Is the bias intensionally harmful or hateful?</li>
      <li>Are you receiving feedback from a wide variety of people?</li>
    </ul>
  </li>
</ul>

<p>Using these questions, software developers are able to reduce harmful bias in algorithms and data.</p>

<h2 id="homework-hacks">Homework Hacks:</h2>
<p>The implementation of a predictive policing algorithm in a city has raised concerns regarding potential biases,leading to disporotionate targeting of specific neighborhoods. This over-policing could result in civil rights violation. Your task is to propose a solution to mitigate this bias and explain the method you’d use to remove computing bias. Make a full paragraph that is at least 4 sentences</p>

<p>Disproportionate targeting in a predictive algorithm usually means that the algorithm’s training dataset is inappropriately skewed towards certain elements of the analyzed dataset, since most useful predictive algorithms these days are trainable neural nets and not primitive hard-coded things. To mitigate this bias, the most important action is to retrain the algorithm with a more representative data set - the old one would have to be discarded. In order to collect such a dataset, I would divide neighborhoods based on individual police administrations and harvest a certain fixed number of records from each police station to serve as the new predictive training dataset. This would reduce the biases towards certain neighborhoods because the training sample is no longer overly weighted towards neighborhoods with higher crime rates, and thus the algorithm is less likely to make inappropriate associations between residents of those neighborhoods and criminal activity.</p>



  <small>tags: <em></em></small>


      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/sfremy">sfremy</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
  </body>
</html>